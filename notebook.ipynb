{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f3231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\"{nara}의 수도는 어디인가요? 그리고 당신의 이름은 무엇인가요?\")\n",
    "\n",
    "prompt = template.format(nara=\"대한민국\")\n",
    "\n",
    "chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f80678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 친절한 AI 비서입니다.\"),\n",
    "    (\"ai\", \"안녕하세요! 저는 지영봇입니다.\") ,\n",
    "    (\"human\", \"{nara}의 수도는 어디인가요? 그리고 당신의 이름은 무엇인가요?\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(nara=\"대한민국\")\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7111c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 요리사입니다. 요리에 대한 레시피를 간단하게 제안합니다.\"),\n",
    "    (\"human\", \"나는 {요리}를 만들기를 원합니다.\")\n",
    "])\n",
    "\n",
    "veg_chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 채식주의자 요리사입니다. 레시피를 채식주의에 맞게 다시 레시피를 간단하게 알려주세요.\"),\n",
    "    (\"human\", \"{레시피}\")\n",
    "])\n",
    "\n",
    "chef_chain = chef_prompt | chat\n",
    "veg_chanin = veg_chef_prompt | chat\n",
    "\n",
    "final_chain = {\"레시피\":chef_chain} | veg_chanin\n",
    "\n",
    "final_chain.invoke({\"요리\":\"김치찌개\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23c8cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "examples =[\n",
    "    {\n",
    "        \"질문\": \"김치찌개 만드는 방법\",\n",
    "        \"답변\": \"김치찌개를 만들기 위해서는 먼저 김치를 준비하고, 돼지고기와 두부를 넣고 끓입니다. 마지막으로 대파와 고춧가루를 넣어 맛을 조절합니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"질문\": \"된장찌개 만드는 방법\",\n",
    "        \"답변\": \"된장찌개를 만들기 위해서는 된장을 풀고, 감자와 호박, 두부를 넣고 끓입니다. 마지막으로 대파와 청양고추를 넣어 맛을 조절합니다.\"   \n",
    "    }\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Human:{질문}\\nAI: {답변}\")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    "    suffix=\"Human: {요리}를 만드는 방법\",\n",
    "    input_variables=[\"요리\"]\n",
    ")\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\"요리\":\"미역국\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8607e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "examples =[\n",
    "    {\n",
    "        \"요리\": \"김치찌개\",\n",
    "        \"답변\": \"김치찌개를 만들기 위해서는 먼저 김치를 준비하고, 돼지고기와 두부를 넣고 끓입니다. 마지막으로 대파와 고춧가루를 넣어 맛을 조절합니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"요리\": \"된장찌개\",\n",
    "        \"답변\": \"된장찌개를 만들기 위해서는 된장을 풀고, 감자와 호박, 두부를 넣고 끓입니다. 마지막으로 대파와 청양고추를 넣어 맛을 조절합니다.\"   \n",
    "    }\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{요리} 만드는 방법은 뭐에요?\"),\n",
    "    (\"ai\", \"{답변}\")\n",
    "])\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 요리사입니다. 요리에 대한 레시피를 간단하게 제안합니다.\"),\n",
    "    example_prompt\n",
    "    (\"human\", \"{요리} 만드는 방법은 뭐에요?\")\n",
    "])\n",
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\"요리\":\"미역국\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e528ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "examples =[\n",
    "    {\n",
    "        \"질문\": \"김치찌개 만드는 방법\",\n",
    "        \"답변\": \"김치찌개를 만들기 위해서는 먼저 김치를 준비하고, 돼지고기와 두부를 넣고 끓입니다. 마지막으로 대파와 고춧가루를 넣어 맛을 조절합니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"질문\": \"된장찌개 만드는 방법\",\n",
    "        \"답변\": \"된장찌개를 만들기 위해서는 된장을 풀고, 감자와 호박, 두부를 넣고 끓입니다. 마지막으로 대파와 청양고추를 넣어 맛을 조절합니다.\"   \n",
    "    }\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Human:{질문}\\nAI: {답변}\")\n",
    "\n",
    "example_selector = LengthBasedExampleSelector.from_examples(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=10,\n",
    ")\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human: {요리}를 만드는 방법\",\n",
    "    input_variables=[\"요리\"]\n",
    ")\n",
    "\n",
    "prompt.format(요리=\"김치찌개\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7838ac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "examples =[\n",
    "    {\n",
    "        \"질문\": \"김치찌개 만드는 방법\",\n",
    "        \"답변\": \"김치찌개를 만들기 위해서는 먼저 김치를 준비하고, 돼지고기와 두부를 넣고 끓입니다. 마지막으로 대파와 고춧가루를 넣어 맛을 조절합니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"질문\": \"된장찌개 만드는 방법\",\n",
    "        \"답변\": \"된장찌개를 만들기 위해서는 된장을 풀고, 감자와 호박, 두부를 넣고 끓입니다. 마지막으로 대파와 청양고추를 넣어 맛을 조절합니다.\"   \n",
    "    }\n",
    "]\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "    \n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "    \n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice\n",
    "        return [choice(self.examples)]\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Human:{질문}\\nAI: {답변}\")\n",
    "\n",
    "example_selector = RandomExampleSelector(\n",
    "    examples=examples\n",
    ")\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human: {요리}를 만드는 방법\",\n",
    "    input_variables=[\"요리\"]\n",
    ")\n",
    "\n",
    "prompt.format(요리=\"김치찌개\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b489134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "prompt = load_prompt(\"./prompt.json\")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "prompt.format(country=\"대한민국\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61cd9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "prompt = load_prompt(\"./prompt.yaml\")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "prompt.format(country=\"대한민국\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d7587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "prompt = load_prompt(\"./prompt.yaml\")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "#총 4개의 프롬프트를 만들거에요.\n",
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    너는 role-playing 어시스턴트야. {charactor}를 흉내내는 AI 비서야.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"이것은 너가 어떻게 말해야하는지에 대한 예제입니다.\n",
    "    Human: {example_question}\n",
    "    You : {example_answer}\n",
    "    \"\"\"\n",
    ")\n",
    "#AI 도우미가 우리의 텍스트를 완성해주는 start 예제\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    start now!\n",
    "    Human: {question}\n",
    "    You:\n",
    "    \"\"\"\n",
    ")\n",
    "#이 모든것을 하나로 합친 prompt\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"{intro}\n",
    "    {example}\n",
    "    {start}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "prompts =[\n",
    "    (\"intro\", intro),\n",
    "    (\"example\", example),\n",
    "    (\"start\", start)\n",
    "]\n",
    "\n",
    "full_prompt = PipelinePromptTemplate(final_prompt=final, pipeline_prompts=prompts)\n",
    "\n",
    "chain = full_prompt | chat\n",
    "chain.invoke({\n",
    "    \"charactor\": \"해적\",\n",
    "    \"example_question\": \"해적이 되려면 어떻게 해야하나요?\",\n",
    "    \"example_answer\": \"크르릉..그것은 비밀이다..!!.\",\n",
    "    \"question\": \"너가 좋아하는 음식은 뭐에요?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa0ea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain.chat_models import ChatOpenAI\n",
    "import langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "#첫번째 질문에 답변과 두번쨰 답변이 걸리는 시간 보기\n",
    "chat.predict(\"이탈리안 파스타는 어떻게 만드는건가요?\") #13초\n",
    "\n",
    "chat.predict(\"이탈리안 파스타는 어떻게 만드는건가요?\") #0.1초\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cf4d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain.chat_models import ChatOpenAI\n",
    "import langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import SQLiteCache\n",
    "\n",
    "set_llm_cache(SQLiteCache(\"cache.db\")) #db 에 캐싱해놓음\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "#첫번째 질문에 답변과 두번쨰 답변이 걸리는 시간 보기\n",
    "chat.predict(\"이탈리안 파스타는 어떻게 만드는건가요?\") #13초\n",
    "\n",
    "chat.predict(\"이탈리안 파스타는 어떻게 만드는건가요?\") #0.1초\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#챌린지예제\n",
    "#영화 이름을 가지고 감독, 주요 출연진, 예산, 흥행 수익, 영화의 장르, 간단한 시놉시스 등 영화에 대한 정보로 답장하는 체인을 만드세요.\n",
    "#LLM은 항상 동일한 형식을 사용하여 응답해야 하며, 이를 위해서는 원하는 출력의 예시를 LLM에 제공해야 합니다.\n",
    "#예제를 제공하려면 FewShotPromptTemplate 또는 FewShotChatMessagePromptTemplate을 사용하세요.\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "examples =[\n",
    "    {\n",
    "        \"영화이름\": \"거룩한밤\",\n",
    "        \"감독\": \"임대희\",\n",
    "        \"주요 출연진\": \"마동석, 서현, 이다윗, 경수진, 정지소\",\n",
    "        \"예산\": \"약 150억원\",\n",
    "        \"흥행 수익\": \"2025년 5월 기준 베트남 30만 관객 돌파\",\n",
    "        \"장르\": \"액션\",\n",
    "        \"시놉시스\": \"악을 숭배하는 집단에 의해 혼란에 빠진 도시에서, 특별한 능력을 가진 어둠의 해결사 '거룩한 밤' 팀(바우, 샤론, 김군)이 의뢰를 받아 악의 무리를 처단하는 오컬트 액션. 신경정신과 의사 정원이 악마에 빙의된 동생 은서를 구해달라고 의뢰하면서 팀이 거대한 악에 맞서 싸우게 된다.\"\n",
    "    },\n",
    "    {\n",
    "        \"영화이름\": \"계시록\",\n",
    "        \"감독\": \"연상호\",\n",
    "        \"주요 출연진\": \"류준열, 신현빈, 신민재, 한지현\",\n",
    "        \"예산\": \"약 1600억원\",\n",
    "        \"흥행 수익\": \"2025년 4월 기준 넷플릭스 공개 직후 글로벌 1위 기록\",\n",
    "        \"장르\": \"범죄\",\n",
    "        \"시놉시스\": \"지방 소도시의 목사 민찬이 신의 계시를 받아 소녀 실종 사건의 범인을 쫓으면서, 형사 연희와 전과자 양래가 얽히고설키는 현실적 범죄 스릴러. 종교적 신념과 집착, 사회의 어두운 면을 조명한다.\"   \n",
    "    },\n",
    "    {\n",
    "        \"영화이름\": \"대홍수\",\n",
    "        \"감독\": \"김병우\",\n",
    "        \"주요 출연진\": \"김다미, 박해수, 이재웅\",\n",
    "        \"예산\": \"비공개\",\n",
    "        \"흥행 수익\": \"비공개\",\n",
    "        \"장르\": \"재난\",\n",
    "        \"시놉시스\": \"지구에 대홍수가 닥치며, 인공지능 개발자 안나와 인적자원 보안팀 희조가 물에 잠긴 아파트에서 생존을 위해 사투를 벌인다. 희조가 안나를 구하려는 이유와 그 배후의 진실이 점차 드러난다.\"   \n",
    "    }\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{영화제목} 에 대하여 영화 정보 알려주세요\"),\n",
    "    (\"ai\", \"{답변}\")\n",
    "])\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 영화정보를 안내해주는 영화안내자입니다. 영화에 대한 정보를 간단하게 제안합니다.\"),\n",
    "    example_prompt\n",
    "    (\"human\", \"{영화제목} 에 대하여 영화 정보 알려주세요\")\n",
    "])\n",
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\"영화제목\":\"도가니\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
